{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lda import guidedlda as glda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Lemmatized Reviews"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "number = 5933\n",
    "lemmatized_data = pd.read_csv(f'../data/reviews/lemmatized_reviews/lemmatized_reviews_{number}.csv', index_col=0)\n",
    "lemmatized_data"
   ],
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "          tconst                username rating  \\\n0      tt0000574               David-240  10/10   \n1      tt0000574  F Gwynplaine MacIntyre  10/10   \n2      tt0000574               ackstasis   9/10   \n3      tt0000574               Ziggy5446  10/10   \n4      tt0000574            Fella_shibby   8/10   \n...          ...                     ...    ...   \n11743  tt0018621          JohnHowardReid   8/10   \n11744  tt0018621                kidboots   8/10   \n11745  tt0018621  F Gwynplaine MacIntyre   7/10   \n11746  tt0018638            cliffperriam   8/10   \n11747  tt0018639  F Gwynplaine MacIntyre   6/10   \n\n                                                  review  \n0      movie be believe to be the world first feature...  \n1      this afternoon at the barbican i attend the uk...  \n2      movie be undoubtedly one of the cinema most si...  \n3      movie symbolizes both the birth of the austral...  \n4      this be the original n the first account of ne...  \n...                                                  ...  \n11743  paramount groom superbeautiful actress a a rep...  \n11744  actress seem to be in every other movie during...  \n11745  actress be an attractive and talented actress ...  \n11746  movie exists a a reel silent french mm release...  \n11747  i be eager to see movie because it base on a p...  \n\n[11748 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tconst</th>\n      <th>username</th>\n      <th>rating</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0000574</td>\n      <td>David-240</td>\n      <td>10/10</td>\n      <td>movie be believe to be the world first feature...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0000574</td>\n      <td>F Gwynplaine MacIntyre</td>\n      <td>10/10</td>\n      <td>this afternoon at the barbican i attend the uk...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0000574</td>\n      <td>ackstasis</td>\n      <td>9/10</td>\n      <td>movie be undoubtedly one of the cinema most si...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0000574</td>\n      <td>Ziggy5446</td>\n      <td>10/10</td>\n      <td>movie symbolizes both the birth of the austral...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0000574</td>\n      <td>Fella_shibby</td>\n      <td>8/10</td>\n      <td>this be the original n the first account of ne...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11743</th>\n      <td>tt0018621</td>\n      <td>JohnHowardReid</td>\n      <td>8/10</td>\n      <td>paramount groom superbeautiful actress a a rep...</td>\n    </tr>\n    <tr>\n      <th>11744</th>\n      <td>tt0018621</td>\n      <td>kidboots</td>\n      <td>8/10</td>\n      <td>actress seem to be in every other movie during...</td>\n    </tr>\n    <tr>\n      <th>11745</th>\n      <td>tt0018621</td>\n      <td>F Gwynplaine MacIntyre</td>\n      <td>7/10</td>\n      <td>actress be an attractive and talented actress ...</td>\n    </tr>\n    <tr>\n      <th>11746</th>\n      <td>tt0018638</td>\n      <td>cliffperriam</td>\n      <td>8/10</td>\n      <td>movie exists a a reel silent french mm release...</td>\n    </tr>\n    <tr>\n      <th>11747</th>\n      <td>tt0018639</td>\n      <td>F Gwynplaine MacIntyre</td>\n      <td>6/10</td>\n      <td>i be eager to see movie because it base on a p...</td>\n    </tr>\n  </tbody>\n</table>\n<p>11748 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Fitted Guided LDA Model\n",
    "\n",
    "In this section, I will be creating a Guided LDA model fitted to the lemmatized reviews.\n",
    "\n",
    "To do this, I have prepared some basic seed words which will then get expanded with similar/correlated words\n",
    "by running GLDA on some guide documents. As the guide documents are already split into the appropriate topics,\n",
    "we can expand the seed words list in this manner with some confidence.\n",
    "\n",
    "An additional GLDA model will then be created, fitted on the entire corpus of reviews. The expanded topic word\n",
    "list will be used as the seed words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_vocab(cv):\n",
    "    \"\"\"\n",
    "    Retrieve the word2id mapping and vocabulary list.\n",
    "\n",
    "    Parameters:\n",
    "    cv (CountVectorizer): sparse matrix representation of word tokens extracted from some corpus of documents.\n",
    "\n",
    "    Returns:\n",
    "    word2id: A mapping of terms to feature indices.\n",
    "    vocab: A list of all unique vocabulary.\n",
    "\n",
    "   \"\"\"\n",
    "    word2id = cv.vocabulary_\n",
    "    vocab = cv.get_feature_names()\n",
    "    return word2id, vocab\n",
    "\n",
    "def fitted_glda_model(X, guide_words, word2id, seed_confidence=1):\n",
    "    \"\"\"\n",
    "    Create a fitted Guided LDA model.\n",
    "\n",
    "    Parameters:\n",
    "    X (sparse matrix): document-term matrix\n",
    "    guide_words (list): 2d array of seed words per topic\n",
    "    word2id (dict): mapping of terms to feature indices\n",
    "    seed_confidence (float): a float from [0,1] that enforces a bias toward the seed words. with a seed_confidence of 0.1 you can bias the seeded words by 10% more\n",
    "\n",
    "    Returns:\n",
    "    A fitted GLDA model\n",
    "\n",
    "   \"\"\"\n",
    "    model = glda.GuidedLDA(n_topics=len(guide_words), n_iter=100)\n",
    "\n",
    "    seed_topics = {}\n",
    "    for t_id, st in enumerate(guide_words):\n",
    "        for word in st:\n",
    "            seed_topics[word2id[word]] = t_id\n",
    "\n",
    "    model.fit(X, seed_topics=seed_topics, seed_confidence=seed_confidence)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_topic_labels(files):\n",
    "    \"\"\"\n",
    "    Gives a list of topic labels given file names of guide documents.\n",
    "    Assumes filenames are written in the form '<path>\\\\<topic_label>.txt'\n",
    "\n",
    "    Parameters:\n",
    "    files (list): list of filepaths\n",
    "\n",
    "    Returns:\n",
    "    list of topic labels\n",
    "\n",
    "   \"\"\"\n",
    "    return [re.findall('\\\\\\\\([a-z_]+)', file)[0].replace('_', ' ') for file in files]\n",
    "\n",
    "def get_guide_words(model, vocab, n, topics):\n",
    "    \"\"\"\n",
    "    Displays and returns top n words of each topic of a fitted GLDA model.\n",
    "\n",
    "    Parameters:\n",
    "    model (GuidedLDA): GLDA model\n",
    "    vocab (list): list of unique vocabulary in corpus\n",
    "    n (int): number of top words to return\n",
    "    topics (list): list of topic labels\n",
    "\n",
    "    Returns:\n",
    "    list of top n guide words per topic\n",
    "\n",
    "   \"\"\"\n",
    "    guide_words = []\n",
    "    for i, topic_dist in enumerate(model.topic_word_):\n",
    "        topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "        guide_words.append(topic_words)\n",
    "        print(f'Topic {topics[i]}:\\n{\" \".join(topic_words)}\\n')\n",
    "\n",
    "    return guide_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve Seed Topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import glob\n",
    "\n",
    "filenames = [file for file in glob.glob(\"../data/topics/lemm_topics/*.txt\")]\n",
    "topic_labels = get_topic_labels(filenames)\n",
    "\n",
    "guide_cv = CountVectorizer(input='filenames', stop_words='english', max_df=0.9)\n",
    "# create document term matrix over all guide documents\n",
    "guide_X = guide_cv.fit_transform(filenames)\n",
    "\n",
    "# create vocabulary over all guide documents\n",
    "guide_word2id, guide_vocab = get_vocab(guide_cv)\n",
    "\n",
    "# retrieve (manual) basic guide words\n",
    "with open('../data/topics/lemm_guide_words.txt', encoding='utf-8') as f:\n",
    "    basic_guide_words = [[t for t in topics.split() if t in guide_vocab] for topics in f.read().splitlines()]\n",
    "\n",
    "# retrieve fitted glda model\n",
    "guide_model = fitted_glda_model(guide_X, basic_guide_words, guide_word2id)\n",
    "\n",
    "# retrieve guide words extracted from all guide documents\n",
    "seed_guide_words = get_guide_words(guide_model, guide_vocab, 10, topic_labels)"
   ],
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 11\n",
      "INFO:lda:vocab_size: 11\n",
      "INFO:lda:n_words: 11\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 100\n",
      "INFO:lda:<0> log likelihood: -54\n",
      "INFO:lda:<10> log likelihood: -56\n",
      "INFO:lda:<20> log likelihood: -54\n",
      "INFO:lda:<30> log likelihood: -56\n",
      "INFO:lda:<40> log likelihood: -61\n",
      "INFO:lda:<50> log likelihood: -56\n",
      "INFO:lda:<60> log likelihood: -54\n",
      "INFO:lda:<70> log likelihood: -54\n",
      "INFO:lda:<80> log likelihood: -54\n",
      "INFO:lda:<90> log likelihood: -57\n",
      "INFO:lda:<99> log likelihood: -56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic acting:\n",
      "sound_music theme_lemm theme plot it_factor editing_effects directing dialogue cinematography attraction\n",
      "\n",
      "Topic attraction:\n",
      "acting theme_lemm theme sound_music plot it_factor editing_effects directing dialogue cinematography\n",
      "\n",
      "Topic cinematography:\n",
      "plot theme_lemm theme sound_music it_factor editing_effects directing dialogue cinematography attraction\n",
      "\n",
      "Topic dialogue:\n",
      "attraction theme_lemm theme sound_music plot it_factor editing_effects directing dialogue cinematography\n",
      "\n",
      "Topic directing:\n",
      "theme_lemm theme sound_music plot it_factor editing_effects directing dialogue cinematography attraction\n",
      "\n",
      "Topic editing effects:\n",
      "editing_effects theme_lemm theme sound_music plot it_factor directing dialogue cinematography attraction\n",
      "\n",
      "Topic it factor:\n",
      "directing dialogue theme_lemm theme sound_music plot it_factor editing_effects cinematography attraction\n",
      "\n",
      "Topic plot:\n",
      "theme theme_lemm sound_music plot it_factor editing_effects directing dialogue cinematography attraction\n",
      "\n",
      "Topic sound music:\n",
      "theme_lemm theme sound_music plot it_factor editing_effects directing dialogue cinematography attraction\n",
      "\n",
      "Topic theme:\n",
      "it_factor cinematography theme_lemm theme sound_music plot editing_effects directing dialogue attraction\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "['acting',\n 'attraction',\n 'cinematography',\n 'dialogue',\n 'directing',\n 'editing_effects',\n 'it_factor',\n 'plot',\n 'sound_music',\n 'theme',\n 'theme_lemm']"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Corpus Vocabulary and Seed Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glda_cv = CountVectorizer(stop_words='english', min_df=30, max_df=0.7)\n",
    "# create document term matrix over all guide documents\n",
    "glda_X = guide_cv.fit_transform(lemmatized_data.review)\n",
    "\n",
    "glda_word2id, glda_vocab = get_vocab(glda_cv)\n",
    "\n",
    "glda_guide_words = [[t for t in topics if t in glda_vocab] for topics in seed_guide_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model and Display Top Topic Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 11748\n",
      "INFO:lda:vocab_size: 73608\n",
      "INFO:lda:n_words: 1591076\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 100\n",
      "INFO:lda:<0> log likelihood: -17841553\n",
      "INFO:lda:<10> log likelihood: -15532555\n",
      "INFO:lda:<20> log likelihood: -14927697\n",
      "INFO:lda:<30> log likelihood: -14696768\n",
      "INFO:lda:<40> log likelihood: -14565792\n",
      "INFO:lda:<50> log likelihood: -14475953\n",
      "INFO:lda:<60> log likelihood: -14405670\n",
      "INFO:lda:<70> log likelihood: -14352188\n",
      "INFO:lda:<80> log likelihood: -14308258\n",
      "INFO:lda:<90> log likelihood: -14275873\n",
      "INFO:lda:<99> log likelihood: -14243286\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 46300 is out of bounds for axis 0 with size 5242",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-101-000a6c8ab9eb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# TODO: cv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mglda_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfitted_glda_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mglda_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglda_guide_words\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglda_word2id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed_confidence\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtop_words\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_guide_words\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mglda_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglda_vocab\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_labels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-96-3f1a3d6a3b3e>\u001B[0m in \u001B[0;36mget_guide_words\u001B[1;34m(model, vocab, n, topics)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[0mguide_words\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_dist\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopic_word_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m         \u001B[0mtopic_words\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtopic_dist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m         \u001B[0mguide_words\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtopic_words\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Topic {topics[i]}:\\n{\" \".join(topic_words)}\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 46300 is out of bounds for axis 0 with size 5242"
     ]
    }
   ],
   "source": [
    "# TODO: cv\n",
    "glda_model = fitted_glda_model(glda_X, glda_guide_words, glda_word2id, seed_confidence=0.8)\n",
    "top_words = get_guide_words(glda_model, glda_vocab, 15, topic_labels)\n",
    "\n",
    "import pickle\n",
    "with open('../pickles/glda.pickle', 'wb') as f:\n",
    "    pickle.dump([glda_model, topic_labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e4b9277d",
   "language": "python",
   "display_name": "PyCharm (movie-preference-predictor)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}